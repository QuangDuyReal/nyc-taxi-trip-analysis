<!DOCTYPE html>
<html>
<head>
<title>Nhom 01 - HungDuyANhHien.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="h%C6%B0%E1%BB%9Bng-d%E1%BA%ABn-%C4%91%E1%BB%93-%C3%A1n-x%E1%BB%AD-l%C3%BD-d%E1%BB%AF-li%E1%BB%87u-l%E1%BB%9Bn-th%E1%BB%9Di-gian-th%E1%BB%B1c-v%E1%BB%9Bi-pyspark">Hướng Dẫn Đồ Án: Xử Lý Dữ Liệu Lớn Thời Gian Thực với PySpark</h1>
<h2 id="th%C3%B4ng-tin-t%E1%BB%95ng-quan"><strong>Thông Tin Tổng Quan</strong></h2>
<h3 id="m%E1%BB%A5c-ti%C3%AAu-%C4%91%E1%BB%93-%C3%A1n"><strong>Mục Tiêu Đồ Án</strong></h3>
<p>Thiết kế và triển khai một pipeline xử lý dữ liệu lớn có khả năng mở rộng và chịu lỗi, sử dụng Apache PySpark với kiến trúc Medallion để phân tích dữ liệu chuyến đi taxi NYC.</p>
<h3 id="ki%E1%BA%BFn-tr%C3%BAc-v%C3%A0-c%C3%B4ng-ngh%E1%BB%87"><strong>Kiến Trúc và Công Nghệ</strong></h3>
<ul>
<li><strong>Framework</strong>: Apache PySpark 3.4+</li>
<li><strong>Kiến trúc</strong>: Medallion (Bronze → Silver → Gold)</li>
<li><strong>Xử lý</strong>: Batch Processing + Streaming Processing</li>
<li><strong>Định dạng dữ liệu</strong>: Parquet, Delta Lake (tuỳ chọn)</li>
<li><strong>Visualization</strong>: Matplotlib, Seaborn, Plotly</li>
<li><strong>Environment</strong>: Jupyter Notebook, Python 3.8+</li>
</ul>
<h3 id="c%E1%BA%A5u-tr%C3%BAc-nh%C3%B3m-v%C3%A0-ph%C3%A2n-c%C3%B4ng"><strong>Cấu Trúc Nhóm và Phân Công</strong></h3>
<ul>
<li><strong>Team Leader/Data Engineer</strong>: Quản lý dự án, thiết kế kiến trúc tổng thể</li>
<li><strong>Data Pipeline Engineer</strong>: Phát triển batch processing pipeline</li>
<li><strong>Streaming Engineer</strong>: Phát triển real-time streaming pipeline</li>
<li><strong>Analytics Engineer</strong>: Data quality, visualization và insight</li>
</ul>
<hr>
<h2 id="ph%E1%BA%A7n-1-chu%E1%BA%A9n-b%E1%BB%8B-d%E1%BB%AF-li%E1%BB%87u-v%C3%A0-m%C3%B4i-tr%C6%B0%E1%BB%9Dng"><strong>Phần 1: Chuẩn Bị Dữ Liệu và Môi Trường</strong></h2>
<h3 id="11-ngu%E1%BB%93n-d%E1%BB%AF-li%E1%BB%87u-ch%C3%ADnh"><strong>1.1 Nguồn Dữ Liệu Chính</strong></h3>
<h4 id="nyc-yellow-taxi-trip-records"><strong>NYC Yellow Taxi Trip Records</strong></h4>
<ul>
<li><strong>Nguồn chính</strong>: NYC Taxi &amp; Limousine Commission (TLC) - https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page</li>
<li><strong>Định dạng</strong>: Parquet files, được cập nhật hàng tháng với độ trễ 2 tháng</li>
<li><strong>Kích thước</strong>: Khoảng 10-15 triệu trips/tháng, ~1-2GB/file</li>
<li><strong>Thời gian</strong>: Dữ liệu từ 2009 đến hiện tại</li>
</ul>
<h4 id="ngu%E1%BB%93n-d%E1%BB%AF-li%E1%BB%87u-b%E1%BB%95-sung"><strong>Nguồn Dữ Liệu Bổ Sung</strong></h4>
<ol>
<li><strong>AWS Open Data</strong>: Registry of Open Data on AWS - nyc-tlc-trip-records-pds</li>
<li><strong>Kaggle</strong>: NYC Yellow Taxi Trip Data datasets</li>
<li><strong>Azure Open Datasets</strong>: Microsoft Azure Open Datasets - NYC Taxi</li>
</ol>
<h3 id="12-schema-d%E1%BB%AF-li%E1%BB%87u-data-dictionary"><strong>1.2 Schema Dữ Liệu (Data Dictionary)</strong></h3>
<p>Theo official TLC data dictionary, dataset chứa các trường sau:</p>
<table>
<thead>
<tr>
<th>Field Name</th>
<th>Data Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>VendorID</td>
<td>Integer</td>
<td>Mã nhà cung cấp TPEP (1=Creative Mobile, 2=Curb Mobility, 6=Myle, 7=Helix)</td>
</tr>
<tr>
<td>tpep_pickup_datetime</td>
<td>Timestamp</td>
<td>Thời gian bắt đầu chuyến đi</td>
</tr>
<tr>
<td>tpep_dropoff_datetime</td>
<td>Timestamp</td>
<td>Thời gian kết thúc chuyến đi</td>
</tr>
<tr>
<td>passenger_count</td>
<td>Integer</td>
<td>Số hành khách</td>
</tr>
<tr>
<td>trip_distance</td>
<td>Double</td>
<td>Khoảng cách chuyến đi (miles)</td>
</tr>
<tr>
<td>RatecodeID</td>
<td>Integer</td>
<td>Mã loại giá (1=Standard, 2=JFK, 3=Newark, 4=Nassau/Westchester, 5=Negotiated, 6=Group)</td>
</tr>
<tr>
<td>store_and_fwd_flag</td>
<td>String</td>
<td>Cờ lưu trữ và chuyển tiếp (Y/N)</td>
</tr>
<tr>
<td>PULocationID</td>
<td>Integer</td>
<td>ID vùng đón khách</td>
</tr>
<tr>
<td>DOLocationID</td>
<td>Integer</td>
<td>ID vùng trả khách</td>
</tr>
<tr>
<td>payment_type</td>
<td>Integer</td>
<td>Loại thanh toán (1=Credit, 2=Cash, 3=No charge, 4=Dispute, 5=Unknown, 6=Voided)</td>
</tr>
<tr>
<td>fare_amount</td>
<td>Double</td>
<td>Cước phí cơ bản</td>
</tr>
<tr>
<td>extra</td>
<td>Double</td>
<td>Phụ phí khác</td>
</tr>
<tr>
<td>mta_tax</td>
<td>Double</td>
<td>Thuế MTA</td>
</tr>
<tr>
<td>tip_amount</td>
<td>Double</td>
<td>Tiền tip</td>
</tr>
<tr>
<td>tolls_amount</td>
<td>Double</td>
<td>Phí cầu đường</td>
</tr>
<tr>
<td>improvement_surcharge</td>
<td>Double</td>
<td>Phụ phí cải thiện</td>
</tr>
<tr>
<td>total_amount</td>
<td>Double</td>
<td>Tổng tiền</td>
</tr>
<tr>
<td>congestion_surcharge</td>
<td>Double</td>
<td>Phụ phí ùn tắc</td>
</tr>
<tr>
<td>airport_fee</td>
<td>Double</td>
<td>Phí sân bay</td>
</tr>
<tr>
<td>cbd_congestion_fee</td>
<td>Double</td>
<td>Phí ùn tắc CBD (từ 2025)</td>
</tr>
</tbody>
</table>
<h3 id="13-c%C3%A0i-%C4%91%E1%BA%B7t-m%C3%B4i-tr%C6%B0%E1%BB%9Dng"><strong>1.3 Cài Đặt Môi Trường</strong></h3>
<pre class="hljs"><code><div><span class="hljs-comment"># requirements.txt</span>
pyspark==<span class="hljs-number">3.4</span><span class="hljs-number">.1</span>
pandas==<span class="hljs-number">2.0</span><span class="hljs-number">.3</span>
matplotlib==<span class="hljs-number">3.7</span><span class="hljs-number">.2</span>
seaborn==<span class="hljs-number">0.12</span><span class="hljs-number">.2</span>
plotly==<span class="hljs-number">5.15</span><span class="hljs-number">.0</span>
jupyter==<span class="hljs-number">1.0</span><span class="hljs-number">.0</span>
delta-spark==<span class="hljs-number">2.4</span><span class="hljs-number">.0</span>
pyarrow==<span class="hljs-number">12.0</span><span class="hljs-number">.1</span>
</div></code></pre>
<pre class="hljs"><code><div><span class="hljs-comment"># Cài đặt Spark</span>
pip install pyspark[sql]
pip install -r requirements.txt

<span class="hljs-comment"># Download sample data</span>
wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet
</div></code></pre>
<hr>
<h2 id="ph%E1%BA%A7n-2-thi%E1%BA%BFt-k%E1%BA%BF-pipeline-theo-ki%E1%BA%BFn-tr%C3%BAc-medallion"><strong>Phần 2: Thiết Kế Pipeline theo Kiến Trúc Medallion</strong></h2>
<h3 id="21-giai-%C4%91o%E1%BA%A1n-1-bronze-layer-raw-data-ingestion"><strong>2.1 Giai Đoạn 1: Bronze Layer (Raw Data Ingestion)</strong></h3>
<h4 id="m%E1%BB%A5c-ti%C3%AAu-nh%E1%BA%ADp-d%E1%BB%AF-li%E1%BB%87u-th%C3%B4-t%E1%BB%AB-nhi%E1%BB%81u-ngu%E1%BB%93n-kh%C3%B4ng-bi%E1%BA%BFn-%C4%91%E1%BB%95i"><strong>Mục tiêu</strong>: Nhập dữ liệu thô từ nhiều nguồn, không biến đổi</h4>
<pre class="hljs"><code><div><span class="hljs-comment"># bronze_layer.py</span>
<span class="hljs-keyword">from</span> pyspark.sql <span class="hljs-keyword">import</span> SparkSession
<span class="hljs-keyword">from</span> pyspark.sql.types <span class="hljs-keyword">import</span> *

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_bronze_pipeline</span><span class="hljs-params">()</span>:</span>
    spark = SparkSession.builder \
        .appName(<span class="hljs-string">"NYC_Taxi_Bronze_Layer"</span>) \
        .config(<span class="hljs-string">"spark.sql.adaptive.enabled"</span>, <span class="hljs-string">"true"</span>) \
        .config(<span class="hljs-string">"spark.sql.adaptive.coalescePartitions.enabled"</span>, <span class="hljs-string">"true"</span>) \
        .getOrCreate()
    
    <span class="hljs-comment"># Schema định nghĩa cho Yellow Taxi</span>
    yellow_taxi_schema = StructType([
        StructField(<span class="hljs-string">"VendorID"</span>, IntegerType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"tpep_pickup_datetime"</span>, TimestampType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"tpep_dropoff_datetime"</span>, TimestampType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"passenger_count"</span>, IntegerType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"trip_distance"</span>, DoubleType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"RatecodeID"</span>, IntegerType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"store_and_fwd_flag"</span>, StringType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"PULocationID"</span>, IntegerType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"DOLocationID"</span>, IntegerType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"payment_type"</span>, IntegerType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"fare_amount"</span>, DoubleType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"extra"</span>, DoubleType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"mta_tax"</span>, DoubleType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"tip_amount"</span>, DoubleType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"tolls_amount"</span>, DoubleType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"improvement_surcharge"</span>, DoubleType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"total_amount"</span>, DoubleType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"congestion_surcharge"</span>, DoubleType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"airport_fee"</span>, DoubleType(), <span class="hljs-literal">True</span>),
        StructField(<span class="hljs-string">"cbd_congestion_fee"</span>, DoubleType(), <span class="hljs-literal">True</span>)
    ])
    
    <span class="hljs-comment"># Đọc dữ liệu từ nhiều nguồn</span>
    df_yellow = spark.read \
        .schema(yellow_taxi_schema) \
        .option(<span class="hljs-string">"multiline"</span>, <span class="hljs-string">"true"</span>) \
        .parquet(<span class="hljs-string">"data/raw/yellow_tripdata_*.parquet"</span>)
    
    <span class="hljs-comment"># Thêm metadata cho tracking</span>
    <span class="hljs-keyword">from</span> pyspark.sql.functions <span class="hljs-keyword">import</span> current_timestamp, lit
    
    df_bronze = df_yellow \
        .withColumn(<span class="hljs-string">"ingestion_timestamp"</span>, current_timestamp()) \
        .withColumn(<span class="hljs-string">"source_file"</span>, lit(<span class="hljs-string">"yellow_taxi"</span>)) \
        .withColumn(<span class="hljs-string">"data_layer"</span>, lit(<span class="hljs-string">"bronze"</span>))
    
    <span class="hljs-comment"># Lưu vào Bronze layer với partitioning</span>
    df_bronze.write \
        .mode(<span class="hljs-string">"overwrite"</span>) \
        .partitionBy(<span class="hljs-string">"year"</span>, <span class="hljs-string">"month"</span>) \
        .parquet(<span class="hljs-string">"data/bronze/yellow_taxi/"</span>)
    
    <span class="hljs-keyword">return</span> df_bronze
</div></code></pre>
<h4 id="y%C3%AAu-c%E1%BA%A7u-bronze-layer"><strong>Yêu cầu Bronze Layer</strong>:</h4>
<ul>
<li>Giữ nguyên dữ liệu gốc, không làm sạch</li>
<li>Thêm metadata: ingestion timestamp, source information</li>
<li>Partition theo năm/tháng để tối ưu performance</li>
<li>Fault-tolerance: checkpointing và error handling</li>
</ul>
<h3 id="22-giai-%C4%91o%E1%BA%A1n-2-silver-layer-data-cleaning--validation"><strong>2.2 Giai Đoạn 2: Silver Layer (Data Cleaning &amp; Validation)</strong></h3>
<h4 id="m%E1%BB%A5c-ti%C3%AAu-l%C3%A0m-s%E1%BA%A1ch-d%E1%BB%AF-li%E1%BB%87u-validate-v%C3%A0-standardize"><strong>Mục tiêu</strong>: Làm sạch dữ liệu, validate và standardize</h4>
<pre class="hljs"><code><div><span class="hljs-comment"># silver_layer.py</span>
<span class="hljs-keyword">from</span> pyspark.sql.functions <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">from</span> pyspark.sql.types <span class="hljs-keyword">import</span> *

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_silver_pipeline</span><span class="hljs-params">(spark, bronze_df)</span>:</span>
    
    <span class="hljs-comment"># Data Quality Rules</span>
    df_silver = bronze_df \
        .filter(col(<span class="hljs-string">"tpep_pickup_datetime"</span>).isNotNull()) \
        .filter(col(<span class="hljs-string">"tpep_dropoff_datetime"</span>).isNotNull()) \
        .filter(col(<span class="hljs-string">"trip_distance"</span>) &gt; <span class="hljs-number">0</span>) \
        .filter(col(<span class="hljs-string">"fare_amount"</span>) &gt; <span class="hljs-number">0</span>) \
        .filter(col(<span class="hljs-string">"total_amount"</span>) &gt; <span class="hljs-number">0</span>) \
        .filter(col(<span class="hljs-string">"passenger_count"</span>).between(<span class="hljs-number">1</span>, <span class="hljs-number">8</span>)) \
        .filter(col(<span class="hljs-string">"PULocationID"</span>).isNotNull()) \
        .filter(col(<span class="hljs-string">"DOLocationID"</span>).isNotNull())
    
    <span class="hljs-comment"># Feature Engineering</span>
    df_silver = df_silver \
        .withColumn(<span class="hljs-string">"trip_duration_minutes"</span>, 
                   (unix_timestamp(<span class="hljs-string">"tpep_dropoff_datetime"</span>) - 
                    unix_timestamp(<span class="hljs-string">"tpep_pickup_datetime"</span>)) / <span class="hljs-number">60</span>) \
        .withColumn(<span class="hljs-string">"pickup_hour"</span>, hour(<span class="hljs-string">"tpep_pickup_datetime"</span>)) \
        .withColumn(<span class="hljs-string">"pickup_day_of_week"</span>, dayofweek(<span class="hljs-string">"tpep_pickup_datetime"</span>)) \
        .withColumn(<span class="hljs-string">"pickup_month"</span>, month(<span class="hljs-string">"tpep_pickup_datetime"</span>)) \
        .withColumn(<span class="hljs-string">"pickup_year"</span>, year(<span class="hljs-string">"tpep_pickup_datetime"</span>)) \
        .withColumn(<span class="hljs-string">"speed_mph"</span>, 
                   when(col(<span class="hljs-string">"trip_duration_minutes"</span>) &gt; <span class="hljs-number">0</span>, 
                        col(<span class="hljs-string">"trip_distance"</span>) / (col(<span class="hljs-string">"trip_duration_minutes"</span>) / <span class="hljs-number">60</span>))
                   .otherwise(<span class="hljs-number">0</span>)) \
        .withColumn(<span class="hljs-string">"tip_percentage"</span>, 
                   when(col(<span class="hljs-string">"fare_amount"</span>) &gt; <span class="hljs-number">0</span>, 
                        col(<span class="hljs-string">"tip_amount"</span>) / col(<span class="hljs-string">"fare_amount"</span>) * <span class="hljs-number">100</span>)
                   .otherwise(<span class="hljs-number">0</span>))
    
    <span class="hljs-comment"># Data Quality Filters</span>
    df_silver = df_silver \
        .filter(col(<span class="hljs-string">"trip_duration_minutes"</span>).between(<span class="hljs-number">1</span>, <span class="hljs-number">180</span>)) \
        .filter(col(<span class="hljs-string">"speed_mph"</span>) &lt; <span class="hljs-number">100</span>) \
        .filter(col(<span class="hljs-string">"tip_percentage"</span>) &lt;= <span class="hljs-number">50</span>)
    
    <span class="hljs-comment"># Add data quality scores</span>
    df_silver = df_silver \
        .withColumn(<span class="hljs-string">"quality_score"</span>, 
                   when((col(<span class="hljs-string">"trip_distance"</span>) &gt; <span class="hljs-number">0</span>) &amp; 
                        (col(<span class="hljs-string">"trip_duration_minutes"</span>) &gt; <span class="hljs-number">0</span>) &amp; 
                        (col(<span class="hljs-string">"fare_amount"</span>) &gt; <span class="hljs-number">0</span>), <span class="hljs-number">1.0</span>)
                   .otherwise(<span class="hljs-number">0.5</span>)) \
        .withColumn(<span class="hljs-string">"processing_timestamp"</span>, current_timestamp())
    
    <span class="hljs-keyword">return</span> df_silver
</div></code></pre>
<h4 id="y%C3%AAu-c%E1%BA%A7u-silver-layer"><strong>Yêu cầu Silver Layer</strong>:</h4>
<ul>
<li>Data validation và outlier detection</li>
<li>Feature engineering cho analysis</li>
<li>Data quality scoring</li>
<li>Standardization của data types</li>
</ul>
<h3 id="23-giai-%C4%91o%E1%BA%A1n-3-gold-layer-business-analytics"><strong>2.3 Giai Đoạn 3: Gold Layer (Business Analytics)</strong></h3>
<h4 id="m%E1%BB%A5c-ti%C3%AAu-t%E1%BA%A1o-ra-business-ready-datasets-cho-ph%C3%A2n-t%C3%ADch"><strong>Mục tiêu</strong>: Tạo ra business-ready datasets cho phân tích</h4>
<pre class="hljs"><code><div><span class="hljs-comment"># gold_layer.py</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_gold_aggregations</span><span class="hljs-params">(spark, silver_df)</span>:</span>
    
    <span class="hljs-comment"># 1. Hourly Trip Analytics</span>
    hourly_stats = silver_df \
        .groupBy(<span class="hljs-string">"pickup_year"</span>, <span class="hljs-string">"pickup_month"</span>, <span class="hljs-string">"pickup_hour"</span>) \
        .agg(
            count(<span class="hljs-string">"*"</span>).alias(<span class="hljs-string">"total_trips"</span>),
            avg(<span class="hljs-string">"fare_amount"</span>).alias(<span class="hljs-string">"avg_fare"</span>),
            avg(<span class="hljs-string">"tip_amount"</span>).alias(<span class="hljs-string">"avg_tip"</span>),
            avg(<span class="hljs-string">"trip_distance"</span>).alias(<span class="hljs-string">"avg_distance"</span>),
            avg(<span class="hljs-string">"trip_duration_minutes"</span>).alias(<span class="hljs-string">"avg_duration"</span>),
            avg(<span class="hljs-string">"passenger_count"</span>).alias(<span class="hljs-string">"avg_passengers"</span>)
        )
    
    <span class="hljs-comment"># 2. Location-based Analytics (Hotspots)</span>
    location_stats = silver_df \
        .groupBy(<span class="hljs-string">"PULocationID"</span>, <span class="hljs-string">"pickup_hour"</span>) \
        .agg(
            count(<span class="hljs-string">"*"</span>).alias(<span class="hljs-string">"pickup_count"</span>),
            avg(<span class="hljs-string">"fare_amount"</span>).alias(<span class="hljs-string">"avg_fare_from_location"</span>),
            avg(<span class="hljs-string">"trip_distance"</span>).alias(<span class="hljs-string">"avg_trip_distance"</span>)
        ) \
        .withColumn(<span class="hljs-string">"pickup_density_rank"</span>, 
                   dense_rank().over(Window.partitionBy(<span class="hljs-string">"pickup_hour"</span>)
                                   .orderBy(desc(<span class="hljs-string">"pickup_count"</span>))))
    
    <span class="hljs-comment"># 3. Payment Analytics</span>
    payment_stats = silver_df \
        .groupBy(<span class="hljs-string">"payment_type"</span>, <span class="hljs-string">"pickup_year"</span>, <span class="hljs-string">"pickup_month"</span>) \
        .agg(
            count(<span class="hljs-string">"*"</span>).alias(<span class="hljs-string">"payment_count"</span>),
            avg(<span class="hljs-string">"total_amount"</span>).alias(<span class="hljs-string">"avg_total_amount"</span>),
            avg(<span class="hljs-string">"tip_amount"</span>).alias(<span class="hljs-string">"avg_tip_amount"</span>),
            sum(<span class="hljs-string">"total_amount"</span>).alias(<span class="hljs-string">"total_revenue"</span>)
        )
    
    <span class="hljs-comment"># 4. Driver Performance Analytics</span>
    vendor_stats = silver_df \
        .groupBy(<span class="hljs-string">"VendorID"</span>, <span class="hljs-string">"pickup_year"</span>, <span class="hljs-string">"pickup_month"</span>) \
        .agg(
            count(<span class="hljs-string">"*"</span>).alias(<span class="hljs-string">"vendor_trip_count"</span>),
            avg(<span class="hljs-string">"trip_distance"</span>).alias(<span class="hljs-string">"avg_trip_distance"</span>),
            avg(<span class="hljs-string">"speed_mph"</span>).alias(<span class="hljs-string">"avg_speed"</span>),
            avg(<span class="hljs-string">"quality_score"</span>).alias(<span class="hljs-string">"avg_quality_score"</span>)
        )
    
    <span class="hljs-comment"># Save Gold Layer Tables</span>
    hourly_stats.write.mode(<span class="hljs-string">"overwrite"</span>).partitionBy(<span class="hljs-string">"pickup_year"</span>, <span class="hljs-string">"pickup_month"</span>) \
        .parquet(<span class="hljs-string">"data/gold/hourly_trip_analytics/"</span>)
    
    location_stats.write.mode(<span class="hljs-string">"overwrite"</span>).partitionBy(<span class="hljs-string">"pickup_hour"</span>) \
        .parquet(<span class="hljs-string">"data/gold/location_hotspots/"</span>)
    
    payment_stats.write.mode(<span class="hljs-string">"overwrite"</span>).partitionBy(<span class="hljs-string">"pickup_year"</span>, <span class="hljs-string">"pickup_month"</span>) \
        .parquet(<span class="hljs-string">"data/gold/payment_analytics/"</span>)
    
    vendor_stats.write.mode(<span class="hljs-string">"overwrite"</span>).partitionBy(<span class="hljs-string">"pickup_year"</span>, <span class="hljs-string">"pickup_month"</span>) \
        .parquet(<span class="hljs-string">"data/gold/vendor_performance/"</span>)
    
    <span class="hljs-keyword">return</span> {
        <span class="hljs-string">"hourly_stats"</span>: hourly_stats,
        <span class="hljs-string">"location_stats"</span>: location_stats,
        <span class="hljs-string">"payment_stats"</span>: payment_stats,
        <span class="hljs-string">"vendor_stats"</span>: vendor_stats
    }
</div></code></pre>
<h3 id="24-giai-%C4%91o%E1%BA%A1n-4-streaming-layer-real-time-processing"><strong>2.4 Giai Đoạn 4: Streaming Layer (Real-time Processing)</strong></h3>
<h4 id="m%E1%BB%A5c-ti%C3%AAu-x%E1%BB%AD-l%C3%BD-d%E1%BB%AF-li%E1%BB%87u-real-time-v%E1%BB%9Bi-structured-streaming"><strong>Mục tiêu</strong>: Xử lý dữ liệu real-time với Structured Streaming</h4>
<pre class="hljs"><code><div><span class="hljs-comment"># streaming_pipeline.py</span>
<span class="hljs-keyword">from</span> pyspark.sql <span class="hljs-keyword">import</span> SparkSession
<span class="hljs-keyword">from</span> pyspark.sql.functions <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">from</span> pyspark.sql.types <span class="hljs-keyword">import</span> *

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_streaming_pipeline</span><span class="hljs-params">()</span>:</span>
    spark = SparkSession.builder \
        .appName(<span class="hljs-string">"NYC_Taxi_Streaming"</span>) \
        .config(<span class="hljs-string">"spark.sql.streaming.checkpointLocation"</span>, <span class="hljs-string">"checkpoint/"</span>) \
        .getOrCreate()
    
    <span class="hljs-comment"># Đọc streaming data từ file source (simulation)</span>
    streaming_df = spark.readStream \
        .format(<span class="hljs-string">"parquet"</span>) \
        .schema(yellow_taxi_schema) \
        .option(<span class="hljs-string">"path"</span>, <span class="hljs-string">"data/streaming_input/"</span>) \
        .option(<span class="hljs-string">"maxFilesPerTrigger"</span>, <span class="hljs-number">1</span>) \
        .load()
    
    <span class="hljs-comment"># Real-time transformations</span>
    streaming_processed = streaming_df \
        .withColumn(<span class="hljs-string">"pickup_hour"</span>, hour(<span class="hljs-string">"tpep_pickup_datetime"</span>)) \
        .withColumn(<span class="hljs-string">"trip_duration_minutes"</span>, 
                   (unix_timestamp(<span class="hljs-string">"tpep_dropoff_datetime"</span>) - 
                    unix_timestamp(<span class="hljs-string">"tpep_pickup_datetime"</span>)) / <span class="hljs-number">60</span>) \
        .filter(col(<span class="hljs-string">"trip_duration_minutes"</span>) &gt; <span class="hljs-number">0</span>)
    
    <span class="hljs-comment"># Real-time aggregations (sliding windows)</span>
    windowed_counts = streaming_processed \
        .withWatermark(<span class="hljs-string">"tpep_pickup_datetime"</span>, <span class="hljs-string">"10 minutes"</span>) \
        .groupBy(
            window(<span class="hljs-string">"tpep_pickup_datetime"</span>, <span class="hljs-string">"5 minutes"</span>, <span class="hljs-string">"1 minute"</span>),
            <span class="hljs-string">"PULocationID"</span>
        ) \
        .agg(
            count(<span class="hljs-string">"*"</span>).alias(<span class="hljs-string">"trip_count"</span>),
            avg(<span class="hljs-string">"fare_amount"</span>).alias(<span class="hljs-string">"avg_fare"</span>),
            avg(<span class="hljs-string">"trip_duration_minutes"</span>).alias(<span class="hljs-string">"avg_duration"</span>)
        ) \
        .withColumn(<span class="hljs-string">"processing_time"</span>, current_timestamp())
    
    <span class="hljs-comment"># Output to console for monitoring</span>
    query_console = windowed_counts.writeStream \
        .outputMode(<span class="hljs-string">"update"</span>) \
        .format(<span class="hljs-string">"console"</span>) \
        .option(<span class="hljs-string">"truncate"</span>, <span class="hljs-literal">False</span>) \
        .trigger(processingTime=<span class="hljs-string">"30 seconds"</span>) \
        .start()
    
    <span class="hljs-comment"># Output to files for persistence</span>
    query_files = windowed_counts.writeStream \
        .outputMode(<span class="hljs-string">"append"</span>) \
        .format(<span class="hljs-string">"parquet"</span>) \
        .option(<span class="hljs-string">"path"</span>, <span class="hljs-string">"data/streaming_output/realtime_aggregations/"</span>) \
        .option(<span class="hljs-string">"checkpointLocation"</span>, <span class="hljs-string">"checkpoint/streaming_agg/"</span>) \
        .trigger(processingTime=<span class="hljs-string">"1 minute"</span>) \
        .start()
    
    <span class="hljs-keyword">return</span> query_console, query_files
</div></code></pre>
<hr>
<h2 id="ph%E1%BA%A7n-3-implementation-guide"><strong>Phần 3: Implementation Guide</strong></h2>
<h3 id="31-c%E1%BA%A5u-tr%C3%BAc-th%C6%B0-m%E1%BB%A5c-d%E1%BB%B1-%C3%A1n"><strong>3.1 Cấu Trúc Thư Mục Dự Án</strong></h3>
<pre class="hljs"><code><div>nyc_taxi_pipeline/
├── data/
│   ├── raw/                    # Raw parquet files
│   ├── bronze/                 # Bronze layer
│   ├── silver/                 # Silver layer
│   ├── gold/                   # Gold layer
│   └── streaming_input/        # Streaming simulation
├── src/
│   ├── bronze_layer.py
│   ├── silver_layer.py
│   ├── gold_layer.py
│   ├── streaming_pipeline.py
│   ├── data_quality.py
│   └── utils.py
├── notebooks/
│   ├── 01_data_exploration.ipynb
│   ├── 02_pipeline_development.ipynb
│   ├── 03_analytics_dashboard.ipynb
│   └── 04_streaming_demo.ipynb
├── config/
│   ├── spark_config.py
│   └── pipeline_config.yaml
├── tests/
│   ├── test_bronze_layer.py
│   ├── test_silver_layer.py
│   └── test_streaming.py
├── checkpoint/                 # Streaming checkpoints
├── logs/                      # Application logs
├── requirements.txt
├── README.md
└── main_pipeline.py           # Main execution script
</div></code></pre>
<h3 id="32-main-pipeline-execution"><strong>3.2 Main Pipeline Execution</strong></h3>
<pre class="hljs"><code><div><span class="hljs-comment"># main_pipeline.py</span>
<span class="hljs-keyword">from</span> src.bronze_layer <span class="hljs-keyword">import</span> create_bronze_pipeline
<span class="hljs-keyword">from</span> src.silver_layer <span class="hljs-keyword">import</span> create_silver_pipeline
<span class="hljs-keyword">from</span> src.gold_layer <span class="hljs-keyword">import</span> create_gold_aggregations
<span class="hljs-keyword">from</span> src.streaming_pipeline <span class="hljs-keyword">import</span> create_streaming_pipeline
<span class="hljs-keyword">from</span> pyspark.sql <span class="hljs-keyword">import</span> SparkSession
<span class="hljs-keyword">import</span> logging

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-comment"># Setup logging</span>
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    <span class="hljs-comment"># Initialize Spark</span>
    spark = SparkSession.builder \
        .appName(<span class="hljs-string">"NYC_Taxi_Pipeline_Main"</span>) \
        .config(<span class="hljs-string">"spark.sql.adaptive.enabled"</span>, <span class="hljs-string">"true"</span>) \
        .config(<span class="hljs-string">"spark.sql.adaptive.coalescePartitions.enabled"</span>, <span class="hljs-string">"true"</span>) \
        .config(<span class="hljs-string">"spark.sql.adaptive.advisoryPartitionSizeInBytes"</span>, <span class="hljs-string">"128MB"</span>) \
        .getOrCreate()
    
    <span class="hljs-keyword">try</span>:
        <span class="hljs-comment"># Step 1: Bronze Layer</span>
        logger.info(<span class="hljs-string">"Starting Bronze Layer Processing..."</span>)
        bronze_df = create_bronze_pipeline()
        logger.info(<span class="hljs-string">f"Bronze Layer: <span class="hljs-subst">{bronze_df.count()}</span> records processed"</span>)
        
        <span class="hljs-comment"># Step 2: Silver Layer</span>
        logger.info(<span class="hljs-string">"Starting Silver Layer Processing..."</span>)
        silver_df = create_silver_pipeline(spark, bronze_df)
        silver_df.cache()  <span class="hljs-comment"># Cache for multiple uses</span>
        logger.info(<span class="hljs-string">f"Silver Layer: <span class="hljs-subst">{silver_df.count()}</span> records processed"</span>)
        
        <span class="hljs-comment"># Step 3: Gold Layer</span>
        logger.info(<span class="hljs-string">"Starting Gold Layer Processing..."</span>)
        gold_tables = create_gold_aggregations(spark, silver_df)
        logger.info(<span class="hljs-string">"Gold Layer aggregations completed"</span>)
        
        <span class="hljs-comment"># Step 4: Streaming (optional)</span>
        <span class="hljs-keyword">if</span> <span class="hljs-string">"--streaming"</span> <span class="hljs-keyword">in</span> sys.argv:
            logger.info(<span class="hljs-string">"Starting Streaming Pipeline..."</span>)
            query_console, query_files = create_streaming_pipeline()
            query_console.awaitTermination()
            
    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
        logger.error(<span class="hljs-string">f"Pipeline execution failed: <span class="hljs-subst">{str(e)}</span>"</span>)
        <span class="hljs-keyword">raise</span>
    <span class="hljs-keyword">finally</span>:
        spark.stop()

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    main()
</div></code></pre>
<h3 id="33-data-quality-framework"><strong>3.3 Data Quality Framework</strong></h3>
<pre class="hljs"><code><div><span class="hljs-comment"># data_quality.py</span>
<span class="hljs-keyword">from</span> pyspark.sql.functions <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">from</span> pyspark.sql.types <span class="hljs-keyword">import</span> *

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DataQualityChecker</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, spark_session)</span>:</span>
        self.spark = spark_session
    
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">check_data_quality</span><span class="hljs-params">(self, df, layer_name)</span>:</span>
        <span class="hljs-string">"""Comprehensive data quality assessment"""</span>
        
        quality_metrics = {}
        
        <span class="hljs-comment"># 1. Completeness Check</span>
        total_rows = df.count()
        <span class="hljs-keyword">for</span> col_name <span class="hljs-keyword">in</span> df.columns:
            null_count = df.filter(col(col_name).isNull()).count()
            quality_metrics[<span class="hljs-string">f"<span class="hljs-subst">{col_name}</span>_completeness"</span>] = (total_rows - null_count) / total_rows
        
        <span class="hljs-comment"># 2. Validity Check</span>
        <span class="hljs-keyword">if</span> layer_name == <span class="hljs-string">"silver"</span>:
            <span class="hljs-comment"># Business rule validations</span>
            valid_trips = df.filter(
                (col(<span class="hljs-string">"trip_distance"</span>) &gt; <span class="hljs-number">0</span>) &amp;
                (col(<span class="hljs-string">"fare_amount"</span>) &gt; <span class="hljs-number">0</span>) &amp;
                (col(<span class="hljs-string">"trip_duration_minutes"</span>) &gt; <span class="hljs-number">0</span>) &amp;
                (col(<span class="hljs-string">"passenger_count"</span>).between(<span class="hljs-number">1</span>, <span class="hljs-number">8</span>))
            ).count()
            quality_metrics[<span class="hljs-string">"business_rule_validity"</span>] = valid_trips / total_rows
        
        <span class="hljs-comment"># 3. Consistency Check</span>
        amount_consistency = df.filter(
            col(<span class="hljs-string">"total_amount"</span>) &gt;= (col(<span class="hljs-string">"fare_amount"</span>) + col(<span class="hljs-string">"extra"</span>) + col(<span class="hljs-string">"mta_tax"</span>))
        ).count()
        quality_metrics[<span class="hljs-string">"amount_consistency"</span>] = amount_consistency / total_rows
        
        <span class="hljs-comment"># 4. Uniqueness Check (if applicable)</span>
        distinct_rows = df.distinct().count()
        quality_metrics[<span class="hljs-string">"uniqueness"</span>] = distinct_rows / total_rows
        
        <span class="hljs-keyword">return</span> quality_metrics
    
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generate_quality_report</span><span class="hljs-params">(self, quality_metrics)</span>:</span>
        <span class="hljs-string">"""Generate quality report"""</span>
        report = []
        <span class="hljs-keyword">for</span> metric, score <span class="hljs-keyword">in</span> quality_metrics.items():
            status = <span class="hljs-string">"PASS"</span> <span class="hljs-keyword">if</span> score &gt;= <span class="hljs-number">0.95</span> <span class="hljs-keyword">else</span> <span class="hljs-string">"WARN"</span> <span class="hljs-keyword">if</span> score &gt;= <span class="hljs-number">0.8</span> <span class="hljs-keyword">else</span> <span class="hljs-string">"FAIL"</span>
            report.append(<span class="hljs-string">f"<span class="hljs-subst">{metric}</span>: <span class="hljs-subst">{score:<span class="hljs-number">.2</span>%}</span> - <span class="hljs-subst">{status}</span>"</span>)
        
        <span class="hljs-keyword">return</span> <span class="hljs-string">"\n"</span>.join(report)
</div></code></pre>
<hr>
<h2 id="ph%E1%BA%A7n-4-analytics-v%C3%A0-visualization"><strong>Phần 4: Analytics và Visualization</strong></h2>
<h3 id="41-key-performance-indicators-kpis"><strong>4.1 Key Performance Indicators (KPIs)</strong></h3>
<ol>
<li>
<p><strong>Operational KPIs</strong>:</p>
<ul>
<li>Total trips per hour/day</li>
<li>Average trip duration</li>
<li>Average trip distance</li>
<li>Peak hour identification</li>
</ul>
</li>
<li>
<p><strong>Financial KPIs</strong>:</p>
<ul>
<li>Total revenue per period</li>
<li>Average fare per trip</li>
<li>Tip percentage by payment type</li>
<li>Revenue by location zones</li>
</ul>
</li>
<li>
<p><strong>Service Quality KPIs</strong>:</p>
<ul>
<li>Data completeness rates</li>
<li>Processing latency</li>
<li>Error rates in pipeline</li>
</ul>
</li>
</ol>
<h3 id="42-visualization-examples"><strong>4.2 Visualization Examples</strong></h3>
<pre class="hljs"><code><div><span class="hljs-comment"># analytics_dashboard.py</span>
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> plotly.express <span class="hljs-keyword">as</span> px
<span class="hljs-keyword">import</span> plotly.graph_objects <span class="hljs-keyword">as</span> go

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_analytics_dashboard</span><span class="hljs-params">(gold_data)</span>:</span>
    
    <span class="hljs-comment"># 1. Trip Volume Heatmap</span>
    hourly_df = gold_data[<span class="hljs-string">"hourly_stats"</span>].toPandas()
    
    fig, axes = plt.subplots(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">12</span>))
    
    <span class="hljs-comment"># Hourly trip distribution</span>
    axes[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].plot(hourly_df.groupby(<span class="hljs-string">'pickup_hour'</span>)[<span class="hljs-string">'total_trips'</span>].mean())
    axes[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_title(<span class="hljs-string">'Average Trips by Hour of Day'</span>)
    axes[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_xlabel(<span class="hljs-string">'Hour'</span>)
    axes[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_ylabel(<span class="hljs-string">'Number of Trips'</span>)
    
    <span class="hljs-comment"># Fare distribution</span>
    axes[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].hist(hourly_df[<span class="hljs-string">'avg_fare'</span>], bins=<span class="hljs-number">50</span>, alpha=<span class="hljs-number">0.7</span>)
    axes[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_title(<span class="hljs-string">'Distribution of Average Fares'</span>)
    axes[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_xlabel(<span class="hljs-string">'Average Fare ($)'</span>)
    axes[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_ylabel(<span class="hljs-string">'Frequency'</span>)
    
    <span class="hljs-comment"># Location hotspots</span>
    location_df = gold_data[<span class="hljs-string">"location_stats"</span>].toPandas()
    top_locations = location_df.nlargest(<span class="hljs-number">20</span>, <span class="hljs-string">'pickup_count'</span>)
    axes[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].barh(range(len(top_locations)), top_locations[<span class="hljs-string">'pickup_count'</span>])
    axes[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_title(<span class="hljs-string">'Top 20 Pickup Locations'</span>)
    axes[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_xlabel(<span class="hljs-string">'Number of Pickups'</span>)
    
    <span class="hljs-comment"># Payment method analysis</span>
    payment_df = gold_data[<span class="hljs-string">"payment_stats"</span>].toPandas()
    payment_summary = payment_df.groupby(<span class="hljs-string">'payment_type'</span>)[<span class="hljs-string">'payment_count'</span>].sum()
    axes[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].pie(payment_summary.values, labels=payment_summary.index, autopct=<span class="hljs-string">'%1.1f%%'</span>)
    axes[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].set_title(<span class="hljs-string">'Payment Methods Distribution'</span>)
    
    plt.tight_layout()
    plt.savefig(<span class="hljs-string">'analytics_dashboard.png'</span>, dpi=<span class="hljs-number">300</span>, bbox_inches=<span class="hljs-string">'tight'</span>)
    plt.show()

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_interactive_dashboard</span><span class="hljs-params">(gold_data)</span>:</span>
    <span class="hljs-string">"""Create interactive Plotly dashboard"""</span>
    
    hourly_df = gold_data[<span class="hljs-string">"hourly_stats"</span>].toPandas()
    
    <span class="hljs-comment"># Interactive time series</span>
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=hourly_df[<span class="hljs-string">'pickup_hour'</span>],
        y=hourly_df[<span class="hljs-string">'total_trips'</span>],
        mode=<span class="hljs-string">'lines+markers'</span>,
        name=<span class="hljs-string">'Total Trips'</span>,
        line=dict(color=<span class="hljs-string">'blue'</span>, width=<span class="hljs-number">2</span>)
    ))
    
    fig.update_layout(
        title=<span class="hljs-string">'NYC Taxi Trips by Hour'</span>,
        xaxis_title=<span class="hljs-string">'Hour of Day'</span>,
        yaxis_title=<span class="hljs-string">'Number of Trips'</span>,
        hovermode=<span class="hljs-string">'x unified'</span>
    )
    
    fig.show()
</div></code></pre>
<hr>
<h2 id="ph%E1%BA%A7n-5-deliverables-v%C3%A0-assessment"><strong>Phần 5: Deliverables và Assessment</strong></h2>
<h3 id="51-y%C3%AAu-c%E1%BA%A7u-n%E1%BB%99p-b%C3%A0i"><strong>5.1 Yêu Cầu Nộp Bài</strong></h3>
<h4 id="code-deliverables"><strong>Code Deliverables</strong>:</h4>
<ol>
<li><strong>Bronze Layer Script</strong> (<code>bronze_layer.py</code>) - 15 điểm</li>
<li><strong>Silver Layer Script</strong> (<code>silver_layer.py</code>) - 20 điểm</li>
<li><strong>Gold Layer Script</strong> (<code>gold_layer.py</code>) - 20 điểm</li>
<li><strong>Streaming Pipeline</strong> (<code>streaming_pipeline.py</code>) - 20 điểm</li>
<li><strong>Main Pipeline</strong> (<code>main_pipeline.py</code>) - 10 điểm</li>
</ol>
<h4 id="documentation-deliverables"><strong>Documentation Deliverables</strong>:</h4>
<ol>
<li><strong>Technical Documentation</strong> (PDF) - 10 điểm</li>
<li><strong>Analytics Notebook</strong> (Jupyter) - 15 điểm</li>
<li><strong>Data Quality Report</strong> - 10 điểm</li>
</ol>
<h4 id="presentation"><strong>Presentation</strong>:</h4>
<ol>
<li><strong>Live Demo</strong> - 20 điểm</li>
<li><strong>Architecture Explanation</strong> - 10 điểm</li>
<li><strong>Q&amp;A Session</strong> - 10 điểm</li>
</ol>
<h3 id="52-evaluation-criteria"><strong>5.2 Evaluation Criteria</strong></h3>
<table>
<thead>
<tr>
<th>Tiêu chí</th>
<th>Trọng số</th>
<th>Mô tả</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Code Quality</strong></td>
<td>25%</td>
<td>Clean code, documentation, error handling</td>
</tr>
<tr>
<td><strong>Architecture Design</strong></td>
<td>20%</td>
<td>Medallion implementation, scalability</td>
</tr>
<tr>
<td><strong>Data Processing</strong></td>
<td>20%</td>
<td>ETL correctness, performance optimization</td>
</tr>
<tr>
<td><strong>Streaming Implementation</strong></td>
<td>15%</td>
<td>Real-time processing, fault tolerance</td>
</tr>
<tr>
<td><strong>Analytics &amp; Insights</strong></td>
<td>10%</td>
<td>Business value, visualization quality</td>
</tr>
<tr>
<td><strong>Documentation</strong></td>
<td>10%</td>
<td>Technical docs, user guides</td>
</tr>
</tbody>
</table>
<h3 id="53-bonus-points"><strong>5.3 Bonus Points</strong></h3>
<ul>
<li><strong>Delta Lake Integration</strong> (+5 điểm)</li>
<li><strong>Advanced Streaming</strong> (Kafka integration) (+5 điểm)</li>
<li><strong>Machine Learning Pipeline</strong> (+10 điểm)</li>
<li><strong>Cloud Deployment</strong> (AWS/Azure) (+10 điểm)</li>
<li><strong>Advanced Monitoring</strong> (Spark UI analysis) (+5 điểm)</li>
</ul>
<hr>
<h2 id="ph%E1%BA%A7n-6-project-timeline"><strong>Phần 6: Project Timeline</strong></h2>
<h3 id="week-1-2-setup--data-exploration"><strong>Week 1-2: Setup &amp; Data Exploration</strong></h3>
<ul>
<li>Environment setup</li>
<li>Data download và exploration</li>
<li>Team role assignment</li>
<li>Architecture design</li>
</ul>
<h3 id="week-3-4-bronze--silver-layer-development"><strong>Week 3-4: Bronze &amp; Silver Layer Development</strong></h3>
<ul>
<li>Implement data ingestion</li>
<li>Data cleaning và validation</li>
<li>Quality framework setup</li>
<li>Unit testing</li>
</ul>
<h3 id="week-5-6-gold-layer--analytics"><strong>Week 5-6: Gold Layer &amp; Analytics</strong></h3>
<ul>
<li>Business logic implementation</li>
<li>Aggregation pipelines</li>
<li>Analytics development</li>
<li>Performance tuning</li>
</ul>
<h3 id="week-7-8-streaming--integration"><strong>Week 7-8: Streaming &amp; Integration</strong></h3>
<ul>
<li>Streaming pipeline development</li>
<li>End-to-end testing</li>
<li>Documentation</li>
<li>Final presentation prep</li>
</ul>
<hr>
<h2 id="ph%E1%BA%A7n-7-troubleshooting-v%C3%A0-best-practices"><strong>Phần 7: Troubleshooting và Best Practices</strong></h2>
<h3 id="71-common-issues"><strong>7.1 Common Issues</strong></h3>
<ol>
<li>
<p><strong>Memory Issues</strong>:</p>
<pre class="hljs"><code><div><span class="hljs-comment"># Solution: Optimize partitioning and caching</span>
df.repartition(<span class="hljs-number">200</span>).cache()
</div></code></pre>
</li>
<li>
<p><strong>Slow Performance</strong>:</p>
<pre class="hljs"><code><div><span class="hljs-comment"># Solution: Broadcast smaller tables</span>
spark.conf.set(<span class="hljs-string">"spark.sql.adaptive.enabled"</span>, <span class="hljs-string">"true"</span>)
</div></code></pre>
</li>
<li>
<p><strong>Streaming Lag</strong>:</p>
<pre class="hljs"><code><div><span class="hljs-comment"># Solution: Adjust trigger intervals</span>
.trigger(processingTime=<span class="hljs-string">"10 seconds"</span>)
</div></code></pre>
</li>
</ol>
<h3 id="72-performance-optimization"><strong>7.2 Performance Optimization</strong></h3>
<ol>
<li><strong>Partitioning Strategy</strong>: Partition by date columns</li>
<li><strong>Caching</strong>: Cache frequently accessed DataFrames</li>
<li><strong>Broadcast Joins</strong>: For small lookup tables</li>
<li><strong>Adaptive Query Execution</strong>: Enable AQE features</li>
<li><strong>Resource Allocation</strong>: Tune executor memory and cores</li>
</ol>
<h3 id="73-data-quality-best-practices"><strong>7.3 Data Quality Best Practices</strong></h3>
<ol>
<li><strong>Schema Evolution</strong>: Handle schema changes gracefully</li>
<li><strong>Data Validation</strong>: Implement comprehensive checks</li>
<li><strong>Monitoring</strong>: Set up alerts for data quality issues</li>
<li><strong>Recovery</strong>: Implement data recovery mechanisms</li>
</ol>
<hr>
<h2 id="t%C3%A0i-li%E1%BB%87u-tham-kh%E1%BA%A3o"><strong>Tài Liệu Tham Khảo</strong></h2>
<ol>
<li>
<p><strong>Official Documentation</strong>:</p>
<ul>
<li><a href="https://spark.apache.org/docs/latest/">Apache Spark Documentation</a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/">PySpark API Reference</a></li>
</ul>
</li>
<li>
<p><strong>NYC TLC Data Sources</strong>:</p>
<ul>
<li><a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">NYC TLC Trip Record Data</a></li>
<li><a href="https://registry.opendata.aws/nyc-tlc-trip-records-pds/">AWS Open Data Registry</a></li>
</ul>
</li>
<li>
<p><strong>Learning Resources</strong>:</p>
<ul>
<li>Spark: The Definitive Guide</li>
<li>Learning Spark (2nd Edition)</li>
<li>Databricks Academy Training</li>
</ul>
</li>
<li>
<p><strong>Community Resources</strong>:</p>
<ul>
<li>Stack Overflow Spark Tags</li>
<li>Spark User Mailing List</li>
<li>GitHub Spark Examples</li>
</ul>
</li>
</ol>
<hr>
<p><strong>Lưu ý</strong>: Đây là hướng dẫn chi tiết cho đồ án Big Data. Sinh viên cần customize theo yêu cầu cụ thể của trường và có thể mở rộng thêm các tính năng advanced như Machine Learning integration, Cloud deployment, hoặc Real-time Dashboard.</p>

</body>
</html>
